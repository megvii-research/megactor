use_image_encoder: false

pretrained_model_path: "./weights/StableDiffusion"
pretrained_vae_path: "./weights/sd-vae-ft-mse"
pretrained_controlnet_path: ""
pretrained_appearance_encoder_path: "./weights/appearance_encoder"
pretrained_unet_path: ""
motion_module: ""

appearance_controlnet_motion_checkpoint_path: "./weights/checkpoint-steps9000.ckpt"

model_type: "unet_magic_noiseAttenST_Ada"

clip_image_type: "background"
concat_noise_image_type: "origin"
random_seed: 42

do_classifier_free_guidance: true
steps:          25
guidance_scale: 4.5

context:
  context_frames: 16
  context_stride: 1
  context_overlap: 8

inference_config: "configs/inference/magic_inference.yaml"
size: [512, 512]
L:    16

unet_additional_kwargs:
  unet_use_cross_frame_attention: false
  unet_use_temporal_attention: false
  use_motion_module: true
  motion_module_resolutions:
  - 1
  - 2
  - 4
  - 8
  motion_module_mid_block: false
  motion_module_decoder_only: false
  motion_module_type: Vanilla
  motion_module_kwargs:
    num_attention_heads: 8
    num_transformer_block: 1
    attention_block_types:
    - Temporal_Self
    - Temporal_Self
    temporal_position_encoding: true
    temporal_position_encoding_max_len: 32
    temporal_attention_dim_div: 1
  # Addition for image embeddings
  use_image_condition            : true
  use_refer_ada: true


noise_scheduler_kwargs:
  beta_start: 0.00085
  beta_end: 0.012
  beta_schedule: "linear"
